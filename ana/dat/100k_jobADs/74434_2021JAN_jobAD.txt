FAIR scheduler mode is a good way to optimize the execution time of multiple jobs inside one Apache Spark program. Unlike FIFO mode, it shares the resources between tasks and therefore, do not penalize short jobs by the resources lock caused by the long-running jobs.Read also about FAIR jobs scheduling in Apache Spark here:Scheduling Within an Application Spark Schedule: FIFO or FAIR? Scheduling Modeâ€‰â€”â€‰spark.scheduler.mode Spark PropertyIf you liked it, you should read:Apache Spark and shuffle management - external servicesShuffle in Apache Spark, back to the basicsWhat's new in Apache Spark 3.0 - KubernetesShare, like or comment this post on TwitterSome weeks ago during my usual #ApacheSpark configuration analysis I discovered spark.scheduler.mode that can be FIFO (default) or FAIR. I've just published some notes about this property https://t.co/lg8kpFvX09Some weeks ago during my usual #ApacheSpark configuration analysis I discovered spark.scheduler.mode that can be FIFO (default) or FAIR. I've just published some notes about this property https://t.co/lg8kpFvX09â€” Bartosz Konieczny (@waitingforcode) April 4, 2019The comments are moderated. I publish them when I answer, so don't worry if you don't see yours immediately :)Please enable JavaScript to view the comments powered by Disqus.ðŸ“š Newsletter Get new posts, recommended reading and other exclusive information every week. SPAM free - no 3rd party ads, only the information about waitingforcode!SubscribeXData engineeringData processingStorageMessagingCloudJVMSoftware engineeringprivacy policy Â© 2014 - 2021 waitingforcode.com. All rights reserved | Design: Jakub KÄ™dziora"
